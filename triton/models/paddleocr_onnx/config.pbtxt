name: "paddleocr_onnx"
platform: "onnxruntime_onnx"
max_batch_size: 16

input [
  {
    name: "x"
    data_type: TYPE_FP32
    dims: [ 3, 48, 320 ]
  }
]

output [
  {
    name: "save_infer_model/scale_0.tmp_1"
    data_type: TYPE_FP32
    dims: [ -1, 6625 ]
  }
]

version_policy: { all { }}

instance_group [
  {
    count: 4
    kind: KIND_GPU
    gpus: [ 0 ]
  }
]

dynamic_batching {
  preferred_batch_size: [ 8, 16 ]
  max_queue_delay_microseconds: 50000
}